# Sales ETL Pipeline (Python + PostgreSQL)

## ğŸ“Œ Overview

This project implements an **end-to-end ETL pipeline** for ingesting, validating, transforming, and loading sales data using **Python and PostgreSQL**.

The pipeline follows a **Raw â†’ Silver** data architecture and mirrors real-world data engineering patterns used in modern analytics platforms such as **Microsoft Fabric, Databricks, and Airflow-based batch pipelines**.

Key features include:
- File-based ingestion
- Incremental processing using watermarks
- Data quality validation
- Error handling & structured logging
- Idempotent loads using UPSERT logic

---

## ğŸ—ï¸ Architecture

### ğŸ“ Project Structure

```text
data/
â”œâ”€â”€ raw/                     # Incoming JSON files (landing zone)
â”œâ”€â”€ processed/               # Successfully ingested files

etl_pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sales_etl_functions.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ logger.py

logs/
â”œâ”€â”€ sales_etl_logs.log       # Pipeline execution logs
â”œâ”€â”€ invalid_sales.json       # Invalid records with DQ errors
git status
